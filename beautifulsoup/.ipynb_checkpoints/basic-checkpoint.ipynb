{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e8f0e5-66e5-48fb-b27c-b459258f7c84",
   "metadata": {},
   "source": [
    "# BeautifulSoup Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1448e-7fd3-4ed2-9868-12c3e3649126",
   "metadata": {},
   "source": [
    "## Basic exos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c231b79-78a9-4d21-b383-ad2c9cc4d6b7",
   "metadata": {},
   "source": [
    "we will master beautifulsoup with concrete exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b08dfdd-4638-42ea-8c50-08374c6e3569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead604ac-659f-4526-9c00-3e3d3539da64",
   "metadata": {},
   "source": [
    "### 1. Extract the title of a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36cb253-7d35-41c8-b8a2-8e1146937b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub: Let’s build from here · GitHub\n"
     ]
    }
   ],
   "source": [
    "# create a variable containing the URL of the desired website\n",
    "url = \"https://www.github.com\"\n",
    "\n",
    "# send a request to the website and store the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the HTML content of the website using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# extract the title of the website from the parsed HTML\n",
    "title = soup.title.string\n",
    "\n",
    "# print the title of the website\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14a59c-b524-4a6d-9c25-f84a47e93ebd",
   "metadata": {},
   "source": [
    "### 2. Extract all the links from a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1be670-42b8-4911-8f57-b6e6cff8d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.iana.org/domains/example\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.example.com\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "for link in links:\n",
    "    print(link.get(\"href\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36373b-32b1-4eea-91ce-4d345a8401db",
   "metadata": {},
   "source": [
    "### 3. Extract all the images from a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa396d31-7cfc-43b3-adcb-744ee50082b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.github.com\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "images = soup.find_all(\"img\")\n",
    "\n",
    "# for image in images:\n",
    "#     print(image.get(\"src\"))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d5b96-4543-42de-9d27-68113adb57bc",
   "metadata": {},
   "source": [
    "### 4. Extract all the text from a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e5acc1-813f-4b90-ae26-6e2ef4c2bc79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10621\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.github.com\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "text = soup.get_text()\n",
    "\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef77db0-bc60-46dc-b50b-5df59c6a7213",
   "metadata": {},
   "source": [
    "### 5. Extract the first paragraph of a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63b1d2e3-7db5-4c1a-9987-c9a00d6511db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"f1-mktg col-11 col-lg-10 text-normal color-fg-muted mr-lg-n4 mb-3 mb-md-4 mb-md-7 position-relative z-1\">\n",
      "          Harnessed for productivity. Designed for collaboration. Celebrated for built-in security. Welcome to the platform developers love.\n",
      "        </p>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.github.com\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "paragraph = soup.p.string\n",
    "\n",
    "print(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e1bec-da35-4840-be31-df94acaa1e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
