{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26334de6-627d-463e-b5b5-2123f3d4e6b4",
   "metadata": {},
   "source": [
    "# Quotes scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f22506-8e5b-4ded-b21a-47c376b13b35",
   "metadata": {},
   "source": [
    "in this code nootbook i'll be scraping quotes from goodreads based on the type \\\n",
    "i'll store them in a list of dictionnaries so it would be easy for me to stor them as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb4f305-ee61-4759-98bc-d4c9940cfe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42eb1b9-e616-4aab-8c50-83a0bc4f9900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get types of quotes\n",
    "page = 1\n",
    "maxPages = 100\n",
    "url = f'https://www.goodreads.com/quotes/tag/love?page={page}'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# a list contains the tpes of quotes\n",
    "types = []\n",
    "links = soup.select('.listTagsTwoColumn a.gr-hyperlink')\n",
    "for link in links:\n",
    "    quoteType = link.text.strip()\n",
    "    quoteLink = '-'.join(quoteType.split()[:-1])\n",
    "    types.append( { 'type':quoteType, 'link':quoteLink.lower() } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95bc378-5e00-4e0f-89b4-612b459b04a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type    0\n",
       "link    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the types to dataFrame\n",
    "tDf = pd.DataFrame(types)\n",
    "tDf.head(2)\n",
    "tDf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59e782e-d2e2-48d7-8412-06f420f77712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love Quotes\n",
      "Love Quotes 300\n"
     ]
    }
   ],
   "source": [
    "# make a GET request to the HTML page\n",
    "# this code will scrap 30*2000 = 60000 quotes\n",
    "maxPages = 100\n",
    "quotes = []\n",
    "breakIt = False\n",
    "for quoteType in tDf.values:\n",
    "    for i in range(1,maxPages+1):\n",
    "        page = requests.get(f'https://www.goodreads.com/quotes/tag/{quoteType[1]}/?page={i}')\n",
    "        # create a BeautifulSoup object from the page content\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # find all the card elements on the page\n",
    "        cards = soup.find_all('div', class_='quote')\n",
    "        # loop through each card element and extract its data\n",
    "        for card in cards:\n",
    "            title = re.sub('[^A-Za-z0-9]+', ' ', card.find('div', class_='quoteText').text.split('â€•')[0])\n",
    "            author = re.sub('[^A-Za-z0-9]+', ' ', card.find('span', class_='authorOrTitle').text)\n",
    "            try:\n",
    "                book = re.sub('[^A-Za-z0-9]+', ' ', card.find('a', class_='authorOrTitle').text)\n",
    "            except:\n",
    "                book = None\n",
    "            tags = []\n",
    "            for t in card.select('.greyText a'):\n",
    "                tags.append(t.text)\n",
    "            # add the card data to the array\n",
    "            quotes.append({\n",
    "                'title': title,\n",
    "                'author': author,\n",
    "                'tags': tags,\n",
    "                'book' : book,\n",
    "                'type': quoteType[0],\n",
    "            })\n",
    "        if(len(quotes)%100==0):\n",
    "            print(quoteType[0])\n",
    "    print(quoteType[0],len(quotes))\n",
    "\n",
    "quotesDf = pd.DataFrame(quotes)\n",
    "quotesDf.to_csv('out/quotes.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d5cfa4c8-7552-44d0-ab33-7e3d7e2ae710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the saved data\n",
    "df = pd.read_csv('out/quotes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44e7400e-33ad-4e44-8832-9202e221c960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spliting and labeling data\n",
    "types = df['type'].unique()\n",
    "for t in types:\n",
    "    dDf = df.loc[df['type'] == t ]\n",
    "    dDf.drop(columns='type')\n",
    "    dDf.to_csv(f'out/{\"-\".join(t.split())}.csv',encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b6589-a1bb-44f9-aa9f-eb6780e81d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
